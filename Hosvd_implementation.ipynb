{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTEHZPflXJkO",
        "outputId": "5388eb36-38a9-4ab4-d808-aa61a43ef0ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorly\n",
            "  Downloading tensorly-0.7.0-py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tensorly) (1.4.1)\n",
            "Collecting nose\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 13.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorly) (1.21.6)\n",
            "Installing collected packages: nose, tensorly\n",
            "Successfully installed nose-1.3.7 tensorly-0.7.0\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "!pip install tensorly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CddSltXfXJkR"
      },
      "source": [
        "\n",
        "# Basic tensor operations\n",
        "\n",
        "Example on how to perform basic tensor operations. Specifically unfolding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C81ZhaJ5XJkS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorly as tl\n",
        "from tensorly.testing import assert_array_equal\n",
        "from numpy import linalg as LA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The unfolding can be done in different ways. The following is a function that defines the unfolding in the way Dr. Kolda defines it."
      ],
      "metadata": {
        "id": "NyAfwL7sY1T7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f_unfold(tensor, mode=0):\n",
        "    \"\"\"Unfolds a tensors following the Kolda and Bader definition\n",
        "\n",
        "        Moves the `mode` axis to the beginning and reshapes in Fortran order\n",
        "    \"\"\"\n",
        "    return np.reshape(np.moveaxis(tensor, mode, 0), \n",
        "                      (tensor.shape[mode], -1), order='F')\n"
      ],
      "metadata": {
        "id": "9ncC1DrTm7QC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNk5h522XJkS"
      },
      "source": [
        "A tensor is simply a numpy array. Here is a simple example\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRQyp72kXJkS",
        "outputId": "f8298832-b3be-4461-cb7b-9977c2aae5e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* original tensor:\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]\n",
            "  [10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]\n",
            "  [30 31 32 33 34]\n",
            "  [35 36 37 38 39]]\n",
            "\n",
            " [[40 41 42 43 44]\n",
            "  [45 46 47 48 49]\n",
            "  [50 51 52 53 54]\n",
            "  [55 56 57 58 59]]]\n",
            "(3, 4, 5)\n"
          ]
        }
      ],
      "source": [
        "rank_3_tensor = tl.tensor(np.arange(60).reshape((3, 4, 5)))\n",
        "print('* original tensor:\\n{}'.format(rank_3_tensor))\n",
        "print(rank_3_tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiqE9zAmXJkT"
      },
      "source": [
        "**Tesnor unfolding**\n",
        "\n",
        "We can unfold each tensor using the tensorly unfolding or the definition provided before. After the unfolding is done we can then calculate the gram matrices (X*X')to begin implementing the HOSVD Algorithm as shown below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCQsKAxmXJkT",
        "outputId": "41139990-f9f8-4174-a288-e8c84806ee8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* mode-0 unfolding:\n",
            "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
            " [20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n",
            " [40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59]]\n",
            "* mode-0 gram matrix X Xt:\n",
            "[[ 2470  6270 10070]\n",
            " [ 6270 18070 29870]\n",
            " [10070 29870 49670]] \n",
            "\n",
            "* mode-1 unfolding:\n",
            "[[ 0  1  2  3  4 20 21 22 23 24 40 41 42 43 44]\n",
            " [ 5  6  7  8  9 25 26 27 28 29 45 46 47 48 49]\n",
            " [10 11 12 13 14 30 31 32 33 34 50 51 52 53 54]\n",
            " [15 16 17 18 19 35 36 37 38 39 55 56 57 58 59]]\n",
            "* mode-1 gram matrix X Xt:\n",
            "[[11290 12940 14590 16240]\n",
            " [12940 14965 16990 19015]\n",
            " [14590 16990 19390 21790]\n",
            " [16240 19015 21790 24565]] \n",
            "\n",
            "* mode-2 unfolding:\n",
            "[[ 0  5 10 15 20 25 30 35 40 45 50 55]\n",
            " [ 1  6 11 16 21 26 31 36 41 46 51 56]\n",
            " [ 2  7 12 17 22 27 32 37 42 47 52 57]\n",
            " [ 3  8 13 18 23 28 33 38 43 48 53 58]\n",
            " [ 4  9 14 19 24 29 34 39 44 49 54 59]]\n",
            "* mode-2 gram matrix X Xt:\n",
            "[[12650 12980 13310 13640 13970]\n",
            " [12980 13322 13664 14006 14348]\n",
            " [13310 13664 14018 14372 14726]\n",
            " [13640 14006 14372 14738 15104]\n",
            " [13970 14348 14726 15104 15482]] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for mode in range(rank_3_tensor.ndim):\n",
        "  unfolded=tl.unfold(rank_3_tensor, mode)\n",
        "\n",
        "  print('* mode-{} unfolding:\\n{}'.format(mode, unfolded))\n",
        "  gram=np.matmul(unfolded,np.transpose(unfolded))\n",
        "  print('* mode-{} gram matrix X Xt:\\n{} \\n'.format(mode, gram))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HOSVD Algorithm\n",
        "\n",
        "To implement the algorithm we must:\n",
        "\n",
        "\n",
        "1.   Define a Tolerance value that we must satisfy. This value will dictate the SNR of the compression, the final size of the core tensor and the compression ratio. \n",
        "2.   Calculate the gram matrix for the n-th mode.\n",
        "3.   Find the eigen vector and the eigen values of each gram matrix\n",
        "4.   Do a shrink operation to the orginal core tensor with the leading left singular values defined by the tolerance treshold calculated on step 1. \n",
        "\n"
      ],
      "metadata": {
        "id": "5Kl58ZxaZiBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Tolerance\n",
        "tol=0.1\n",
        "print('tol = ', tol);\n",
        "\n",
        "## Calculate the treshold: tol^2 ||X||^2 / d\n",
        "\n",
        "#Square the original tensor\n",
        "sqr_x=np.square(rank_3_tensor) \n",
        "\n",
        "#Calculate norm of the resulting tensor.\n",
        "normsqr_x=LA.norm(sqr_x) \n",
        "print('||X||^2 = ', normsqr_x)\n",
        "\n",
        "# compute the treshold\n",
        "eigsum_thresh = np.square(tol) * normsqr_x / 3 \n",
        "print('eigenvalue sum threshold = tol^2 ||X||^2 / d = {} \\n'.format(eigsum_thresh))\n",
        "\n",
        "np.set_printoptions(suppress=True)\n",
        "rank=np.zeros(rank_3_tensor.ndim); # vector to store the n-ranks of the tensor\n",
        "u=[] # List to save each of the factor matrices\n",
        "\n",
        "\n",
        "#Loop to calculate the gram, eigen and ttm of each mode\n",
        "for mode in range(rank_3_tensor.ndim):\n",
        "\n",
        "  unfolded=tl.unfold(rank_3_tensor, mode) #Matrix unfolding\n",
        "  #print('* mode-{} unfolding:\\n{}'.format(mode, unfolded))\n",
        "\n",
        "  #Right side SVD\n",
        "  #gram=np.matmul( np.transpose(unfolded),unfolded)\n",
        "\n",
        "  #left side SVD\n",
        "  gram=np.matmul(unfolded,np.transpose(unfolded))\n",
        "  \n",
        "  #print(\"unfolded matrix shape: \", unfolded.shape,\" gram shape: \", gram.shape)\n",
        "  #print('Eigen Decomposition:')\n",
        "\n",
        "  #Calculate eigendecomposition of gram matrix where d is the resulting eigenvector and v is the eigenmatrix\n",
        "  d, v = LA.eig(gram)\n",
        "\n",
        "  #print(\"D shape: \", d.shape,\" V shape: \", v.shape)\n",
        "  #print('* D-{} \\n'.format(d))\n",
        "  #print('eigen vector: ', list(map('{:.4f}'.format,d)))\n",
        "\n",
        "  #Reverse sort the resulting eigenvector d\n",
        "  eigvec = np.msort(d)[::-1]\n",
        "  pi=np.argsort(d)[::-1] #keep a record of the original position of the values\n",
        "  \n",
        "  #print('eigen vector sorted: ', list(map('{:.4f}'.format,eigvec)))\n",
        "  #Do a cumulative sum on the sorted eigenvector and find the first value that satisfies the intended tolerance\n",
        "  eigsum = np.cumsum(eigvec[::-1],axis=0)[::-1] \n",
        "  print('Reverse cummulative sum of evals of Gram matrix: ', list(map('{:.4f}'.format,eigsum)),'\\n')\n",
        "\n",
        "  rank[mode]=np.count_nonzero(d > eigsum_thresh)\n",
        "  print('* rank:{:.0f} \\n'.format(np.count_nonzero(d > eigsum_thresh)))\n",
        "  \n",
        "  #Extract factor matrix by picking out leading eigenvectors of V\n",
        "  #u= v[:,pi[0:int(rank[mode])]]\n",
        "  u.append(v[:,pi[0:int(rank[mode])]])\n",
        "  #print('* mode-{} V:\\n{}'.format(mode, v))\n",
        "  #print('* mode-{} U:\\n{}'.format(mode, u))\n",
        "\n",
        "for i in range(rank_3_tensor.ndim):\n",
        "  print('factor matrix {} \\n'.format(i),u[i])\n",
        "print('core dimensions: ', rank)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EWmkwN1k8Oi",
        "outputId": "b5a46ef9-d5f8-4533-9693-a3e7d5c1e900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tol =  0.1\n",
            "||X||^2 =  12211.142370802168\n",
            "eigenvalue sum threshold = tol^2 ||X||^2 / d = 40.7038079026739 \n",
            "\n",
            "Reverse cummulative sum of evals of Gram matrix:  ['70210.0000', '457.6188', '-0.0000'] \n",
            "\n",
            "* rank:2 \n",
            "\n",
            "Reverse cummulative sum of evals of Gram matrix:  ['70210.0000', '433.1667', '-0.0000', '-0.0000'] \n",
            "\n",
            "* rank:2 \n",
            "\n",
            "Reverse cummulative sum of evals of Gram matrix:  ['70210.0000+0.0000j', '30.5645+0.0000j', '-0.0000+0.0000j', '-0.0000-0.0000j', '-0.0000+0.0000j'] \n",
            "\n",
            "* rank:1 \n",
            "\n",
            "factor matrix 0 \n",
            " [[-0.1736132  -0.89620968]\n",
            " [-0.50849656 -0.27343112]\n",
            " [-0.84337993  0.34934743]]\n",
            "factor matrix 1 \n",
            " [[-0.39804473  0.73590787]\n",
            " [-0.46253128  0.29336806]\n",
            " [-0.52701782 -0.14917175]\n",
            " [-0.59150437 -0.59171157]]\n",
            "factor matrix 2 \n",
            " [[-0.42434579+0.j]\n",
            " [-0.4356371 +0.j]\n",
            " [-0.44692842+0.j]\n",
            " [-0.45821974+0.j]\n",
            " [-0.46951105+0.j]]\n",
            "core dimensions:  [2. 2. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hMZ6ttaXJkU"
      },
      "source": [
        "Re-folding the tensor :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cF56wEnpXJkU"
      },
      "outputs": [],
      "source": [
        "#for mode in range(tensor.ndim):\n",
        "#    unfolding = tl.unfold(tensor, mode)\n",
        "#    folded = tl.fold(unfolding, mode, tensor.shape)\n",
        "#    assert_array_equal(folded, tensor)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rank_3_tensor = tl.tensor([\n",
        "  [[0,  1, 2, 3, 4],\n",
        "   [5, 6, 7, 8, 9]],\n",
        "  [[10, 11, 12, 13, 14],\n",
        "   [15, 16, 17, 18, 19]],\n",
        "  [[20, 21, 22, 23, 24],\n",
        "   [25, 26, 27, 28, 29]],])\n",
        "\n",
        "#print(rank_3_tensor)\n",
        "print(rank_3_tensor.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAUjLzZu2uJu",
        "outputId": "d1359ab0-8e7d-43ec-d420-ee61cdf6c5e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 2, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Created with matlab using:\n",
        "#info = create_problem('Type','Tucker','Num_Factors',[3 2 2],'Size',[10 10 2],'Noise',0.01);\n",
        "#This core should be size [3 2 2] ideally\n",
        "rank_3_tensor = tl.tensor([\n",
        "  [[3.2522, -4.1194,  1.2773, -3.4837, -4.4533,  4.7328,  1.3861,  0.4443, -2.1840, -6.1272],\n",
        "    [-0.4372,  0.4523, -0.1801,  0.3506,  0.6150, -0.5485, -0.2036, -0.0384,  0.2677,  0.8703],\n",
        "    [0.2775, -3.1669,  0.3043, -3.4528, -0.3776,  2.7690, -0.6667,  0.8877, -0.1961,  0.0847],\n",
        "    [0.0167,  0.1729, -0.0152,  0.2226, -0.0143, -0.1579,  0.0721, -0.0666,  0.0023, -0.0278],\n",
        "    [1.0922, -3.4406,  0.5798, -3.5065, -1.4925,  3.3778, -0.0935,  0.7749, -0.7153, -1.6531],\n",
        "    [0.8745, -1.7865,  0.3781, -1.7098, -1.2048,  1.8367,  0.1772,  0.2986, -0.5721, -1.5406],\n",
        "    [-0.9146, -0.0432, -0.2478, -0.3934,  1.2757, -0.3010, -0.7167,  0.2394,  0.5652,  1.9942],\n",
        "    [-2.1805,  4.1096, -0.9373,  3.8902,  2.9985, -4.2962, -0.5381, -0.6754,  1.4527,  3.8672],\n",
        "    [0.8677, -0.4320,  0.3031, -0.1894, -1.2001,  0.7128,  0.5873, -0.0587, -0.5794, -1.8024],\n",
        "    [ 2.6731, -2.5217,  0.9804, -1.9389, -3.6152,  3.1858,  1.3655,  0.1010, -1.7614, -5.2084]],\n",
        "  [[-0.2445, -0.8008, -0.0117, -1.0115,  0.3563,  0.6202, -0.4362,  0.3165,  0.1588,  0.7068],\n",
        "    [ 1.1509, -1.2514,  0.4269, -1.0304, -1.5275,  1.5087,  0.5467,  0.0851, -0.7525, -2.1983],\n",
        "    [ 2.1465, -0.7872,  0.6829, -0.1133, -2.9405,  1.4708,  1.4438, -0.2966, -1.4053, -4.4658],\n",
        "    [-0.7661,  0.8491, -0.2896,  0.7289,  1.0558, -0.9995, -0.3729, -0.0540,  0.5241,  1.4674],\n",
        "    [ 0.3347,  0.7940,  0.0531,  1.0016, -0.4026, -0.5319,  0.4581, -0.3045, -0.1692, -0.8015],\n",
        "    [ 0.4765, -0.4281,  0.1920, -0.2992, -0.6741,  0.5294,  0.2539,  0.0084, -0.3225, -0.9158],\n",
        "    [-0.6519,  2.0948, -0.3479,  2.1176,  0.8676, -1.9890,  0.0600, -0.4751,  0.4440,  0.9244],\n",
        "    [ 0.0289, -0.3310,  0.0608, -0.3153, -0.0723,  0.3096, -0.0571,  0.0815, -0.0474, -0.0329],\n",
        "    [-0.2608, -0.5183, -0.0233, -0.6519,  0.3278,  0.3481, -0.3351,  0.2207,  0.1501,  0.6372],\n",
        "    [-0.0018, -1.5616,  0.0955, -1.7584, -0.0166,  1.3316, -0.4397,  0.4832,  0.0005,  0.3300]],])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZffHFCXVKoaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sqr_x=np.square(rank_3_tensor)\n",
        "normsqr_x=LA.norm(sqr_x)\n",
        "tol=0.1\n",
        "\n",
        "eigsum_thresh = np.square(tol) * normsqr_x / 3\n",
        "\n",
        "\n",
        "print('||X||^2 = ', normsqr_x)\n",
        "print('tol = ', tol);\n",
        "print('eigenvalue sum threshold = tol^2 ||X||^2 / d = ', eigsum_thresh)\n",
        "\n",
        "print('eigenvalue sum threshold = tol^2 ||X||^2 / d = {} \\n'.format(eigsum_thresh))\n",
        "np.set_printoptions(suppress=True)\n",
        "rank=np.zeros(rank_3_tensor.ndim);\n",
        "u=[]\n",
        "\n",
        "for mode in range(rank_3_tensor.ndim):\n",
        "  unfolded=tl.unfold(rank_3_tensor, mode)\n",
        "  #print('* mode-{} unfolding:\\n{}'.format(mode, unfolded))\n",
        "\n",
        "  #right side SVD\n",
        "  #gram=np.matmul( np.transpose(unfolded),unfolded)\n",
        "\n",
        "  #left side SVD\n",
        "  gram=np.matmul(unfolded,np.transpose(unfolded))\n",
        "  \n",
        "  print(\"unfolded matrix shape: \", unfolded.shape,\" gram shape: \", gram.shape)\n",
        "  print('Eigen Decomposition:')\n",
        "\n",
        "  d, v = LA.eig(gram)\n",
        "\n",
        "  print(\"D shape: \", d.shape,\" V shape: \", v.shape)\n",
        "  #print('* D-{} \\n'.format(d))\n",
        "  print('eigen vector: ', list(map('{:.4f}'.format,d)))\n",
        "\n",
        "  #Reverse sort\n",
        "  eigvec = np.msort(d)[::-1]\n",
        "  pi=np.argsort(d)[::-1]\n",
        "  \n",
        "  print('eigen vector sorted: ', list(map('{:.4f}'.format,eigvec)))\n",
        "  eigsum = np.cumsum(eigvec[::-1],axis=0)[::-1]\n",
        "  print('Reverse cummulative sum of evals of Gram matrix: ', list(map('{:.4f}'.format,eigsum)),'\\n')\n",
        "\n",
        "  rank[mode]=np.count_nonzero(d > eigsum_thresh)\n",
        "  print('* rank:{:.0f} \\n'.format(np.count_nonzero(d > eigsum_thresh)))\n",
        "  \n",
        "  #Extract factor matrix by picking out leading eigenvectors of V\n",
        "  #u= v[:,pi[0:int(rank[mode])]]\n",
        "  u.append(v[:,pi[0:int(rank[mode])]])\n",
        "  #print('* mode-{} V:\\n{}'.format(mode, v))\n",
        "  #print('* mode-{} U:\\n{}'.format(mode, u))\n",
        "\n",
        "y=rank_3_tensor\n",
        "for i in range(rank_3_tensor.ndim):\n",
        "  print('factor matrix {} \\n'.format(i),u[i])\n",
        "  y = tl.tenalg.mode_dot(y,u[i],i,True)\n",
        "print('core dimensions: ', rank)\n",
        "print('core: ', y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmwApkbgGbsp",
        "outputId": "c17601fe-dafa-4326-b193-c523fd12e0e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "||X||^2 =  81.51622739015059\n",
            "tol =  0.1\n",
            "eigenvalue sum threshold = tol^2 ||X||^2 / d =  0.2717207579671687\n",
            "eigenvalue sum threshold = tol^2 ||X||^2 / d = 0.2717207579671687 \n",
            "\n",
            "unfolded matrix shape:  (2, 100)  gram shape:  (2, 2)\n",
            "Eigen Decomposition:\n",
            "D shape:  (2,)  V shape:  (2, 2)\n",
            "eigen vector:  ['390.6772', '94.9242']\n",
            "eigen vector sorted:  ['390.6772', '94.9242']\n",
            "Reverse cummulative sum of evals of Gram matrix:  ['485.6014', '94.9242'] \n",
            "\n",
            "* rank:2 \n",
            "\n",
            "unfolded matrix shape:  (10, 20)  gram shape:  (10, 10)\n",
            "Eigen Decomposition:\n",
            "D shape:  (10,)  V shape:  (10, 10)\n",
            "eigen vector:  ['361.5971', '78.7988', '45.1758', '0.0095', '0.0070', '0.0010', '0.0015', '0.0026', '0.0039', '0.0043']\n",
            "eigen vector sorted:  ['361.5971', '78.7988', '45.1758', '0.0095', '0.0070', '0.0043', '0.0039', '0.0026', '0.0015', '0.0010']\n",
            "Reverse cummulative sum of evals of Gram matrix:  ['485.6014', '124.0043', '45.2055', '0.0297', '0.0202', '0.0132', '0.0089', '0.0050', '0.0024', '0.0010'] \n",
            "\n",
            "* rank:3 \n",
            "\n",
            "unfolded matrix shape:  (10, 20)  gram shape:  (10, 10)\n",
            "Eigen Decomposition:\n",
            "D shape:  (10,)  V shape:  (10, 10)\n",
            "eigen vector:  ['422.1628', '63.4056', '0.0087', '0.0078', '0.0066', '0.0036', '0.0023', '0.0016', '0.0009', '0.0012']\n",
            "eigen vector sorted:  ['422.1628', '63.4056', '0.0087', '0.0078', '0.0066', '0.0036', '0.0023', '0.0016', '0.0012', '0.0009']\n",
            "Reverse cummulative sum of evals of Gram matrix:  ['485.6014', '63.4385', '0.0329', '0.0241', '0.0164', '0.0097', '0.0061', '0.0038', '0.0022', '0.0009'] \n",
            "\n",
            "* rank:2 \n",
            "\n",
            "factor matrix 0 \n",
            " [[ 0.99932295 -0.0367919 ]\n",
            " [ 0.0367919   0.99932295]]\n",
            "factor matrix 1 \n",
            " [[-0.59044849  0.24596273 -0.06556906]\n",
            " [ 0.04730401 -0.35932786 -0.3509593 ]\n",
            " [-0.24401476 -0.79820606  0.04165746]\n",
            " [ 0.02817672  0.23463214  0.21528085]\n",
            " [-0.31256144 -0.17063987  0.43873466]\n",
            " [-0.20688001 -0.13602913 -0.01509801]\n",
            " [ 0.12352468  0.0507919   0.61925813]\n",
            " [ 0.46727715 -0.03834735 -0.30377493]\n",
            " [-0.12175994  0.16391439 -0.15232208]\n",
            " [-0.44706824  0.1991495  -0.36437504]]\n",
            "factor matrix 2 \n",
            " [[ 0.27147607 -0.20203304]\n",
            " [-0.3988059  -0.39949912]\n",
            " [ 0.10959104 -0.03126916]\n",
            " [-0.3548415  -0.52078071]\n",
            " [-0.37095422  0.27421775]\n",
            " [ 0.44168569  0.26196896]\n",
            " [ 0.10008976 -0.26736199]\n",
            " [ 0.05277043  0.17014051]\n",
            " [-0.18031528  0.12876986]\n",
            " [-0.50132061  0.51629233]]\n",
            "core dimensions:  [2. 3. 2.]\n",
            "core:  [[[-18.88956165  -0.71717651]\n",
            "  [  0.62697903  -4.39652475]\n",
            "  [  0.46249918   3.65973425]]\n",
            "\n",
            " [[ -1.93323025  -0.72693023]\n",
            "  [ -6.20228384   4.53950215]\n",
            "  [ -4.74706157  -3.00537724]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorly.decomposition import tucker\n",
        "random_state = 12345\n",
        "tucker_rank = [2, 3, 2]\n",
        "core, tucker_factors = tucker(rank_3_tensor, rank=tucker_rank, init='random', tol=10e-2, random_state=random_state)\n",
        "print(core.shape)\n",
        "print(core,'\\n')\n",
        "print(tucker_factors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrGGqVwqJG6p",
        "outputId": "c98b699f-af6c-4898-e3b3-75623d85f789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 3, 2)\n",
            "[[[-18.88954736  -0.71716682]\n",
            "  [ -0.62703125   4.3966007 ]\n",
            "  [ -0.46258461  -3.65969945]]\n",
            "\n",
            " [[  1.93337048   0.72693804]\n",
            "  [ -6.20221753   4.53951204]\n",
            "  [ -4.74713278  -3.00529393]]] \n",
            "\n",
            "[array([[-0.99932319, -0.03678541],\n",
            "       [-0.03678541,  0.99932319]]), array([[-0.59044919, -0.24595615,  0.06556455],\n",
            "       [ 0.04730365,  0.35932742,  0.35097667],\n",
            "       [-0.2440164 ,  0.79820934, -0.04164871],\n",
            "       [ 0.02817768, -0.23463187, -0.21527775],\n",
            "       [-0.31255822,  0.17064934, -0.43872624],\n",
            "       [-0.20688132,  0.13602222,  0.01508896],\n",
            "       [ 0.12352529, -0.05077191, -0.6192479 ],\n",
            "       [ 0.46727659,  0.03835802,  0.30378395],\n",
            "       [-0.12176162, -0.16390774,  0.15231531],\n",
            "       [-0.44706802, -0.19915068,  0.36438515]]), array([[-0.27147609,  0.20202982],\n",
            "       [ 0.3988059 ,  0.39950253],\n",
            "       [-0.10959108,  0.03127499],\n",
            "       [ 0.3548415 ,  0.52078643],\n",
            "       [ 0.37095423, -0.27421204],\n",
            "       [-0.44168568, -0.26195878],\n",
            "       [-0.1000899 ,  0.26736744],\n",
            "       [-0.05277053, -0.17013378],\n",
            "       [ 0.18031537, -0.12877532],\n",
            "       [ 0.50132052, -0.51629107]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decomposition comparison\n",
        "for i in range(rank_3_tensor.ndim):\n",
        "  print('factor matrix {} \\n'.format(i),u[i])\n",
        "  print('tensorly: \\n',tucker_factors[i],'\\n')\n",
        "\n",
        "print('core{} \\n'.format(i),y)\n",
        "print('tensorly: \\n',core,'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3XRjgXfK5HT",
        "outputId": "fa680227-19cc-42ff-9adc-398ecf5215ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "factor matrix 0 \n",
            " [[ 0.99932295 -0.0367919 ]\n",
            " [ 0.0367919   0.99932295]]\n",
            "tensorly: \n",
            " [[-0.99932319 -0.03678541]\n",
            " [-0.03678541  0.99932319]] \n",
            "\n",
            "factor matrix 1 \n",
            " [[-0.59044849  0.24596273 -0.06556906]\n",
            " [ 0.04730401 -0.35932786 -0.3509593 ]\n",
            " [-0.24401476 -0.79820606  0.04165746]\n",
            " [ 0.02817672  0.23463214  0.21528085]\n",
            " [-0.31256144 -0.17063987  0.43873466]\n",
            " [-0.20688001 -0.13602913 -0.01509801]\n",
            " [ 0.12352468  0.0507919   0.61925813]\n",
            " [ 0.46727715 -0.03834735 -0.30377493]\n",
            " [-0.12175994  0.16391439 -0.15232208]\n",
            " [-0.44706824  0.1991495  -0.36437504]]\n",
            "tensorly: \n",
            " [[-0.59044919 -0.24595615  0.06556455]\n",
            " [ 0.04730365  0.35932742  0.35097667]\n",
            " [-0.2440164   0.79820934 -0.04164871]\n",
            " [ 0.02817768 -0.23463187 -0.21527775]\n",
            " [-0.31255822  0.17064934 -0.43872624]\n",
            " [-0.20688132  0.13602222  0.01508896]\n",
            " [ 0.12352529 -0.05077191 -0.6192479 ]\n",
            " [ 0.46727659  0.03835802  0.30378395]\n",
            " [-0.12176162 -0.16390774  0.15231531]\n",
            " [-0.44706802 -0.19915068  0.36438515]] \n",
            "\n",
            "factor matrix 2 \n",
            " [[ 0.27147607 -0.20203304]\n",
            " [-0.3988059  -0.39949912]\n",
            " [ 0.10959104 -0.03126916]\n",
            " [-0.3548415  -0.52078071]\n",
            " [-0.37095422  0.27421775]\n",
            " [ 0.44168569  0.26196896]\n",
            " [ 0.10008976 -0.26736199]\n",
            " [ 0.05277043  0.17014051]\n",
            " [-0.18031528  0.12876986]\n",
            " [-0.50132061  0.51629233]]\n",
            "tensorly: \n",
            " [[-0.27147609  0.20202982]\n",
            " [ 0.3988059   0.39950253]\n",
            " [-0.10959108  0.03127499]\n",
            " [ 0.3548415   0.52078643]\n",
            " [ 0.37095423 -0.27421204]\n",
            " [-0.44168568 -0.26195878]\n",
            " [-0.1000899   0.26736744]\n",
            " [-0.05277053 -0.17013378]\n",
            " [ 0.18031537 -0.12877532]\n",
            " [ 0.50132052 -0.51629107]] \n",
            "\n",
            "core2 \n",
            " [[[-18.88956165  -0.71717651]\n",
            "  [  0.62697903  -4.39652475]\n",
            "  [  0.46249918   3.65973425]]\n",
            "\n",
            " [[ -1.93323025  -0.72693023]\n",
            "  [ -6.20228384   4.53950215]\n",
            "  [ -4.74706157  -3.00537724]]]\n",
            "tensorly: \n",
            " [[[-18.88954736  -0.71716682]\n",
            "  [ -0.62703125   4.3966007 ]\n",
            "  [ -0.46258461  -3.65969945]]\n",
            "\n",
            " [[  1.93337048   0.72693804]\n",
            "  [ -6.20221753   4.53951204]\n",
            "  [ -4.74713278  -3.00529393]]] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor reconstruction\n",
        "x1=y\n",
        "for i in range(y.ndim):\n",
        "  x1 = tl.tenalg.mode_dot(x1,u[i],i)\n",
        "  print('mode: ',i)\n",
        "  print('updated core shape: ', x1.shape)\n",
        "\n",
        "print('Reconstructed tensor: ', x1)\n",
        "print('Original tensor: ', rank_3_tensor)\n",
        "\n",
        "\n",
        "# Tolerance calculation\n",
        "diff_sqr = np.square(rank_3_tensor-x1)\n",
        "diff_normsqr = LA.norm(diff_sqr)\n",
        "relnorm = np.sqrt(diff_normsqr/normsqr_x);\n",
        "\n",
        "print('||X-T||/||X|| = ', relnorm, '<= ',tol)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQk6Yv8StsoC",
        "outputId": "49de6616-63fb-4ba5-8700-83d75e7e4d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mode:  0\n",
            "updated core shape:  (2, 3, 2)\n",
            "mode:  1\n",
            "updated core shape:  (2, 10, 2)\n",
            "mode:  2\n",
            "updated core shape:  (2, 10, 10)\n",
            "Reconstructed tensor:  [[[ 3.25438004 -4.11135722  1.26539923 -3.49917902 -4.44512072\n",
            "    4.72693081  1.38527932  0.43126731 -2.15635775 -6.14737412]\n",
            "  [-0.44288233  0.4530367  -0.1645161   0.35618433  0.60464551\n",
            "   -0.55295914 -0.21801255 -0.02666906  0.29262564  0.85848239]\n",
            "  [ 0.26656832 -3.15279907  0.30703404 -3.46083438 -0.37157302\n",
            "    2.7760627  -0.66658197  0.88225918 -0.19855351  0.07564798]\n",
            "  [ 0.00405067  0.18786484 -0.01236286  0.21317274 -0.00502082\n",
            "   -0.1578256   0.05518093 -0.05750337 -0.00118147 -0.04734281]\n",
            "  [ 1.09720018 -3.45486042  0.57603545 -3.51159513 -1.5041412\n",
            "    3.34859653 -0.10600525  0.76757993 -0.74311331 -1.64707727]\n",
            "  [ 0.87932644 -1.78348911  0.39048644 -1.7036309  -1.20284629\n",
            "    1.84778909  0.18798447  0.31881742 -0.58787995 -1.5226694 ]\n",
            "  [-0.91915924 -0.05372721 -0.26964967 -0.38115949  1.2522462\n",
            "   -0.3044239  -0.72779431  0.24358864  0.59957737  1.98612798]\n",
            "  [-2.18595547  4.11089528 -0.94741637  3.87131996  2.98935119\n",
            "   -4.31969971 -0.55672349 -0.69549146  1.45892319  3.85165197]\n",
            "  [ 0.88332717 -0.43600088  0.29435647 -0.18335652 -1.20472282\n",
            "    0.70622189  0.56434619 -0.08743495 -0.58000031 -1.80840848]\n",
            "  [ 2.66417302 -2.54018125  0.97628507 -1.9340224  -3.63677364\n",
            "    3.16934164  1.36272813  0.10476635 -1.75885807 -5.20229372]]\n",
            "\n",
            " [[-0.25230656 -0.81904338 -0.01592889 -1.01122313  0.34160434\n",
            "    0.59873007 -0.42256993  0.30875943  0.15832023  0.7106085 ]\n",
            "  [ 1.14036334 -1.25692265  0.43013713 -1.01904053 -1.55712192\n",
            "    1.50049512  0.53630869  0.09586142 -0.7541762  -2.19188285]\n",
            "  [ 2.15115651 -0.77343669  0.69601714 -0.12149861 -2.9330827\n",
            "    1.47524221  1.45422004 -0.2996521  -1.41022307 -4.46330253]\n",
            "  [-0.76799561  0.85828841 -0.29053442  0.69958308  1.04869951\n",
            "   -1.02053709 -0.35791851 -0.0681065   0.50800363  1.4737322 ]\n",
            "  [ 0.30351729  0.78641056  0.03352541  0.99230172 -0.41146742\n",
            "   -0.55154702  0.45325023 -0.31161618 -0.19200291 -0.81393775]\n",
            "  [ 0.47495442 -0.42197114  0.17181667 -0.30998086 -0.64826251\n",
            "    0.53881839  0.25149334  0.00939029 -0.31331933 -0.93378784]\n",
            "  [-0.63508176  2.0799231  -0.3392119   2.12296057  0.87084019\n",
            "   -2.00625311  0.08356803 -0.46840522  0.43075334  0.93687097]\n",
            "  [ 0.04976412 -0.31813157  0.0377858  -0.3412381  -0.06864941\n",
            "    0.28882426 -0.04952581  0.08336607 -0.0349612  -0.04150134]\n",
            "  [-0.24415874 -0.50869474 -0.03591872 -0.65855847  0.33132591\n",
            "    0.33856012 -0.33028277  0.2134048   0.1554179   0.62927012]\n",
            "  [-0.00264338 -1.56490151  0.11223629 -1.7648676  -0.00054967\n",
            "    1.32651837 -0.43553313  0.47130442 -0.01045839  0.32753852]]]\n",
            "Original tensor:  [[[ 3.2522 -4.1194  1.2773 -3.4837 -4.4533  4.7328  1.3861  0.4443\n",
            "   -2.184  -6.1272]\n",
            "  [-0.4372  0.4523 -0.1801  0.3506  0.615  -0.5485 -0.2036 -0.0384\n",
            "    0.2677  0.8703]\n",
            "  [ 0.2775 -3.1669  0.3043 -3.4528 -0.3776  2.769  -0.6667  0.8877\n",
            "   -0.1961  0.0847]\n",
            "  [ 0.0167  0.1729 -0.0152  0.2226 -0.0143 -0.1579  0.0721 -0.0666\n",
            "    0.0023 -0.0278]\n",
            "  [ 1.0922 -3.4406  0.5798 -3.5065 -1.4925  3.3778 -0.0935  0.7749\n",
            "   -0.7153 -1.6531]\n",
            "  [ 0.8745 -1.7865  0.3781 -1.7098 -1.2048  1.8367  0.1772  0.2986\n",
            "   -0.5721 -1.5406]\n",
            "  [-0.9146 -0.0432 -0.2478 -0.3934  1.2757 -0.301  -0.7167  0.2394\n",
            "    0.5652  1.9942]\n",
            "  [-2.1805  4.1096 -0.9373  3.8902  2.9985 -4.2962 -0.5381 -0.6754\n",
            "    1.4527  3.8672]\n",
            "  [ 0.8677 -0.432   0.3031 -0.1894 -1.2001  0.7128  0.5873 -0.0587\n",
            "   -0.5794 -1.8024]\n",
            "  [ 2.6731 -2.5217  0.9804 -1.9389 -3.6152  3.1858  1.3655  0.101\n",
            "   -1.7614 -5.2084]]\n",
            "\n",
            " [[-0.2445 -0.8008 -0.0117 -1.0115  0.3563  0.6202 -0.4362  0.3165\n",
            "    0.1588  0.7068]\n",
            "  [ 1.1509 -1.2514  0.4269 -1.0304 -1.5275  1.5087  0.5467  0.0851\n",
            "   -0.7525 -2.1983]\n",
            "  [ 2.1465 -0.7872  0.6829 -0.1133 -2.9405  1.4708  1.4438 -0.2966\n",
            "   -1.4053 -4.4658]\n",
            "  [-0.7661  0.8491 -0.2896  0.7289  1.0558 -0.9995 -0.3729 -0.054\n",
            "    0.5241  1.4674]\n",
            "  [ 0.3347  0.794   0.0531  1.0016 -0.4026 -0.5319  0.4581 -0.3045\n",
            "   -0.1692 -0.8015]\n",
            "  [ 0.4765 -0.4281  0.192  -0.2992 -0.6741  0.5294  0.2539  0.0084\n",
            "   -0.3225 -0.9158]\n",
            "  [-0.6519  2.0948 -0.3479  2.1176  0.8676 -1.989   0.06   -0.4751\n",
            "    0.444   0.9244]\n",
            "  [ 0.0289 -0.331   0.0608 -0.3153 -0.0723  0.3096 -0.0571  0.0815\n",
            "   -0.0474 -0.0329]\n",
            "  [-0.2608 -0.5183 -0.0233 -0.6519  0.3278  0.3481 -0.3351  0.2207\n",
            "    0.1501  0.6372]\n",
            "  [-0.0018 -1.5616  0.0955 -1.7584 -0.0166  1.3316 -0.4397  0.4832\n",
            "    0.0005  0.33  ]]]\n",
            "||X-T||/||X|| =  0.006850012316217859 <=  0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor reconstruction\n",
        "\n",
        "tensorly_reconstruction = tl.tucker_to_tensor((core, tucker_factors))\n",
        "print('Reconstructed tensor: ', tensorly_reconstruction)\n",
        "print('Original tensor: ', rank_3_tensor)\n",
        "\n",
        "\n",
        "# Tolerance calculation\n",
        "diff_sqr = np.square(rank_3_tensor-tensorly_reconstruction)\n",
        "diff_normsqr = LA.norm(diff_sqr)\n",
        "relnorm = np.sqrt(diff_normsqr/normsqr_x);\n",
        "\n",
        "print('||X-T||/||X|| = ', relnorm, '<= ',tol)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21cf0d4a-3da4-495c-e61d-4df17710027a",
        "id": "eYnJHWLGYH_A"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructed tensor:  [[[ 3.25437189 -4.1113715   1.26540498 -3.49919517 -4.44510821\n",
            "    4.72695334  1.38527715  0.43128146 -2.15636073 -6.14735686]\n",
            "  [-0.44288283  0.45305859 -0.16451987  0.356208    0.60464584\n",
            "   -0.55298193 -0.21800903 -0.02667764  0.2926284   0.85848015]\n",
            "  [ 0.26658209 -3.1528263   0.30701233 -3.46087221 -0.37159699\n",
            "    2.77603429 -0.66660612  0.88223673 -0.19853289  0.07564418]\n",
            "  [ 0.00405518  0.18788177 -0.01236079  0.21319423 -0.00502656\n",
            "   -0.15783425  0.05519105 -0.05750765 -0.00118639 -0.04735739]\n",
            "  [ 1.09719671 -3.4548454   0.57601491 -3.5115874  -1.5041398\n",
            "    3.34854452 -0.10602158  0.76755844 -0.74309129 -1.64705894]\n",
            "  [ 0.87933591 -1.7835088   0.39048584 -1.70365195 -1.20286011\n",
            "    1.84779924  0.18798188  0.31881646 -0.58788121 -1.52268168]\n",
            "  [-0.91915558 -0.05374073 -0.26966186 -0.38117948  1.25223849\n",
            "   -0.30443982 -0.72780956  0.24357756  0.59959034  1.9861326 ]\n",
            "  [-2.18597288  4.1108935  -0.94741262  3.87131583  2.98937646\n",
            "   -4.31968618 -0.55672954 -0.69547853  1.45892543  3.85168208]\n",
            "  [ 0.88331789 -0.43602858  0.29436449 -0.18338728 -1.20470858\n",
            "    0.70625949  0.56434027 -0.08741546 -0.58000405 -1.80838863]\n",
            "  [ 2.66416582 -2.54014876  0.97629474 -1.93398244 -3.63676102\n",
            "    3.16933937  1.36274639  0.10477294 -1.75886876 -5.20229354]]\n",
            "\n",
            " [[-0.25228014 -0.81905613 -0.01593212 -1.01123342  0.34156606\n",
            "    0.59872653 -0.42256489  0.30874486  0.15831584  0.71056285]\n",
            "  [ 1.1403801  -1.25696083  0.43014923 -1.01907595 -1.55714402\n",
            "    1.5005424   0.53631578  0.09587332 -0.75419229 -2.19191346]\n",
            "  [ 2.15115312 -0.77342618  0.69603967 -0.1214777  -2.93307347\n",
            "    1.47528089  1.45424498 -0.29963    -1.41024723 -4.46331365]\n",
            "  [-0.76799666  0.85827096 -0.29053629  0.69956191  1.04870035\n",
            "   -1.02052818 -0.35792719 -0.06810395  0.50800733  1.47373963]\n",
            "  [ 0.30352591  0.78639542  0.03354152  0.99229298 -0.4114769\n",
            "   -0.5515056   0.45326509 -0.31160145 -0.19202209 -0.81396197]\n",
            "  [ 0.47492989 -0.42193557  0.17180964 -0.30994814 -0.64822845\n",
            "    0.53878451  0.25148711  0.00938857 -0.31330617 -0.9337442 ]\n",
            "  [-0.63504847  2.07988682 -0.3391879   2.12293627  0.87079683\n",
            "   -2.00618605  0.0835949  -0.46839143  0.43071909  0.93679823]\n",
            "  [ 0.04980643 -0.31816495  0.03779834 -0.34126203 -0.0687076\n",
            "    0.28886366 -0.04950465  0.08336324 -0.03498644 -0.04158358]\n",
            "  [-0.24413469 -0.50869386 -0.03592039 -0.65855284  0.33129152\n",
            "    0.33855073 -0.3302726   0.21338991  0.15541168  0.62922445]\n",
            "  [-0.00261698 -1.56495232  0.11223202 -1.76492246 -0.0005887\n",
            "    1.3265393  -0.43554231  0.47129764 -0.01045903  0.32750365]]]\n",
            "Original tensor:  [[[ 3.2522 -4.1194  1.2773 -3.4837 -4.4533  4.7328  1.3861  0.4443\n",
            "   -2.184  -6.1272]\n",
            "  [-0.4372  0.4523 -0.1801  0.3506  0.615  -0.5485 -0.2036 -0.0384\n",
            "    0.2677  0.8703]\n",
            "  [ 0.2775 -3.1669  0.3043 -3.4528 -0.3776  2.769  -0.6667  0.8877\n",
            "   -0.1961  0.0847]\n",
            "  [ 0.0167  0.1729 -0.0152  0.2226 -0.0143 -0.1579  0.0721 -0.0666\n",
            "    0.0023 -0.0278]\n",
            "  [ 1.0922 -3.4406  0.5798 -3.5065 -1.4925  3.3778 -0.0935  0.7749\n",
            "   -0.7153 -1.6531]\n",
            "  [ 0.8745 -1.7865  0.3781 -1.7098 -1.2048  1.8367  0.1772  0.2986\n",
            "   -0.5721 -1.5406]\n",
            "  [-0.9146 -0.0432 -0.2478 -0.3934  1.2757 -0.301  -0.7167  0.2394\n",
            "    0.5652  1.9942]\n",
            "  [-2.1805  4.1096 -0.9373  3.8902  2.9985 -4.2962 -0.5381 -0.6754\n",
            "    1.4527  3.8672]\n",
            "  [ 0.8677 -0.432   0.3031 -0.1894 -1.2001  0.7128  0.5873 -0.0587\n",
            "   -0.5794 -1.8024]\n",
            "  [ 2.6731 -2.5217  0.9804 -1.9389 -3.6152  3.1858  1.3655  0.101\n",
            "   -1.7614 -5.2084]]\n",
            "\n",
            " [[-0.2445 -0.8008 -0.0117 -1.0115  0.3563  0.6202 -0.4362  0.3165\n",
            "    0.1588  0.7068]\n",
            "  [ 1.1509 -1.2514  0.4269 -1.0304 -1.5275  1.5087  0.5467  0.0851\n",
            "   -0.7525 -2.1983]\n",
            "  [ 2.1465 -0.7872  0.6829 -0.1133 -2.9405  1.4708  1.4438 -0.2966\n",
            "   -1.4053 -4.4658]\n",
            "  [-0.7661  0.8491 -0.2896  0.7289  1.0558 -0.9995 -0.3729 -0.054\n",
            "    0.5241  1.4674]\n",
            "  [ 0.3347  0.794   0.0531  1.0016 -0.4026 -0.5319  0.4581 -0.3045\n",
            "   -0.1692 -0.8015]\n",
            "  [ 0.4765 -0.4281  0.192  -0.2992 -0.6741  0.5294  0.2539  0.0084\n",
            "   -0.3225 -0.9158]\n",
            "  [-0.6519  2.0948 -0.3479  2.1176  0.8676 -1.989   0.06   -0.4751\n",
            "    0.444   0.9244]\n",
            "  [ 0.0289 -0.331   0.0608 -0.3153 -0.0723  0.3096 -0.0571  0.0815\n",
            "   -0.0474 -0.0329]\n",
            "  [-0.2608 -0.5183 -0.0233 -0.6519  0.3278  0.3481 -0.3351  0.2207\n",
            "    0.1501  0.6372]\n",
            "  [-0.0018 -1.5616  0.0955 -1.7584 -0.0166  1.3316 -0.4397  0.4832\n",
            "    0.0005  0.33  ]]]\n",
            "||X-T||/||X|| =  0.006850876193185979 <=  0.1\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "Hosvd_implementation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}